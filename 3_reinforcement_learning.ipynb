{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589389e6-2aad-45b6-bc03-e9b37ab1514f",
   "metadata": {},
   "source": [
    "# Reinforcement learning for legged robots\n",
    "\n",
    "In this notebook, \n",
    "\n",
    "## Setup\n",
    "\n",
    "Before we start, you will need to update your conda environment to use Gymnasium (maintained) rather than OpenAI Gym (discontinued). You can simply run:\n",
    "\n",
    "```\n",
    "conda activate robotics-mva\n",
    "conda install gymnasium tensorboard\n",
    "```\n",
    "\n",
    "Import Gymnasium to check that everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3fa7b15-843f-4696-9bfc-141da71bf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e16a1-bf4a-403b-8709-3da11bc3c4b4",
   "metadata": {},
   "source": [
    "# Inverted pendulum environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5d942-85fa-435e-b5ef-8c85a74ba3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gym.make(\"InvertedPendulum-v4\", render_mode=\"human\") as env:\n",
    "    action = 0.0 * env.action_space.sample()\n",
    "    observation, _ = env.reset()\n",
    "    for step in range(500):\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b1ba4-5611-4fc2-b9bb-850ea8748d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c4dd0df-6dc7-4d51-b29b-c77b49bde437",
   "metadata": {},
   "source": [
    "# Bonus: train for a real robot\n",
    "\n",
    "In this section we follow the same training pipeline but with the open source software of [Upkie](https://hackaday.io/project/185729-upkie-wheeled-biped-robots). It is completely optional and will only work on Linux or macOS.\n",
    "\n",
    "## Setup\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/1189580/170496331-e1293dd3-b50c-40ee-9c2e-f75f3096ebd8.png\" style=\"height: 100px\" align=\"right\" />\n",
    "\n",
    "First, make sure you have a C++ compiler (setup one-liners: [Fedora](https://github.com/upkie/upkie/discussions/100), [Ubuntu](https://github.com/upkie/upkie/discussions/101)). You can run an Upkie simulation right from the command line. It won't install anything on your machine, everything will run locally from the repository:\n",
    "\n",
    "```console\n",
    "git clone https://github.com/upkie/upkie.git\n",
    "cd upkie\n",
    "./start_simulation.sh\n",
    "```\n",
    "\n",
    "We will use the Python API of the robot to test things from this notebook, or from custom scripts. Install it from PyPI in your Conda environment:\n",
    "\n",
    "```\n",
    "pip install upkie\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44abc0-f7e9-4c2b-9d4e-a3579213e138",
   "metadata": {},
   "source": [
    "## Stepping the environment\n",
    "\n",
    "If everything worked well, you should be able to step an environment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acedf0d6-fc2f-43f4-9ff6-a8e12dbd7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-15 14:38:09,585] [\u001b[33;1mwarning\u001b[0m] UpkieGroundVelocity rate limiter is late by -3.500000 [ms] (rate_limiter.py:105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have stepped the environment 1000 times\n",
      "The return of our episode is 1000.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gymW\n",
    "import upkie.envs\n",
    "\n",
    "upkie.envs.register()\n",
    "\n",
    "episode_return = 0.0\n",
    "with gym.make(\"UpkieGroundVelocity-v1\", frequency=200.0) as env:\n",
    "    observation, _ = env.reset()  # connects to the spine (simulator or real robot)\n",
    "    action = 0.0 * env.action_space.sample()\n",
    "    for step in range(1000):\n",
    "        pitch = observation[0]\n",
    "        action[0] = 10.0 * pitch  # 1D action: [ground_velocity]\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        episode_return += reward\n",
    "        if terminated or truncated:\n",
    "            observation, _ = env.reset()\n",
    "\n",
    "print(f\"We have stepped the environment {step + 1} times\")\n",
    "print(f\"The return of our episode is {episode_return}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031343b5-cf94-46ae-98f3-a4c5ebbc037c",
   "metadata": {},
   "source": [
    "(If you see a message \"Waiting for spine /vulp to start\", it means the simulation is not running.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecfd91f-676c-4d6f-beb0-a286dc681ae3",
   "metadata": {},
   "source": [
    "We can double-check the last observation from the episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed6d972f-4cc9-4005-b9a1-4a7433a19938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last observation of the episode is:\n",
      "- Pitch from torso to world: -0.061 rad\n",
      "- Ground position: -0.71 m\n",
      "- Angular velocity from torso to world in torso: -0.042 rad/s\n",
      "- Ground velocity: -0.52 m/s\n"
     ]
    }
   ],
   "source": [
    "def report_last_observation(observation):\n",
    "    print(\"The last observation of the episode is:\")\n",
    "    print(f\"- Pitch from torso to world: {observation[0]:.2} rad\")\n",
    "    print(f\"- Ground position: {observation[1]:.2} m\")\n",
    "    print(f\"- Angular velocity from torso to world in torso: {observation[2]:.2} rad/s\")\n",
    "    print(f\"- Ground velocity: {observation[3]:.2} m/s\")\n",
    "    \n",
    "report_last_observation(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a269e3-d876-4d05-88e5-b0d73be6f939",
   "metadata": {},
   "source": [
    "## Question B1: PID balancer\n",
    "\n",
    "Adapt your code from Question 1 to this environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8e9f1e-f2a1-4a18-aa38-256a425d018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-15 14:37:32,222] [\u001b[33;1mwarning\u001b[0m] UpkieGroundVelocity rate limiter is late by -2.800000 [ms] (rate_limiter.py:105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n",
      "The return of our episode is 0.0\n"
     ]
    }
   ],
   "source": [
    "def policy_b1(observation):\n",
    "    return np.array([0.0])  # replace with your solution\n",
    "\n",
    "\n",
    "def run(policy, nb_steps: int):\n",
    "    episode_return = 0.0\n",
    "    with gym.make(\"UpkieGroundVelocity-v1\", frequency=200.0) as env:\n",
    "        observation, _ = env.reset()  # connects to the spine (simulator or real robot)\n",
    "        for step in range(nb_steps):\n",
    "            action = policy_b1(observation)\n",
    "            observation, reward, terminated, truncated, _ = env.step(action)\n",
    "            if terminated or truncated:\n",
    "                print(\"Fall detected!\")\n",
    "                return episode_return\n",
    "    report_last_observation(observation)\n",
    "    return episode_return\n",
    "\n",
    "\n",
    "episode_return = run(policy_b1, 1000)\n",
    "print(f\"The return of our episode is {episode_return}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999eb22-a94a-4a58-ac06-9a7dbc15a7ee",
   "metadata": {},
   "source": [
    "## Training a new policy\n",
    "\n",
    "The Upkie repository ships three agents based on PID control, model predictive control and reinforcement learning. We now focus on the latter, called the \"PPO balancer\".\n",
    "\n",
    "Check that you can run the training part by running, from the root of the repository:\n",
    "\n",
    "```\n",
    "./tools/bazel run //agents/ppo_balancer:train -- --nb-envs 1 --show\n",
    "```\n",
    "\n",
    "A simulation window should pop, and verbose output from SB3 should be printed to your terminal.\n",
    "\n",
    "By default, training data will be logged to `/tmp`. You can select a different output path by setting the `UPKIE_TRAINING_PATH` environment variable in your shell. For instance:\n",
    "\n",
    "```\n",
    "export UPKIE_TRAINING_PATH=\"${HOME}/src/upkie/training\"\n",
    "```\n",
    "\n",
    "Run TensorBoard from the training directory:\n",
    "\n",
    "```\n",
    "tensorboard --logdir ${UPKIE_TRAINING_PATH}  # or /tmp if you keep the default\n",
    "```\n",
    "\n",
    "### Selecting the number of processes\n",
    "\n",
    "We can increase the number of parallel CPU environments ``--nb-envs`` to a value suitable to your computer. Let training run for a minute and check `time/fps`. Increase the number of environments and compare the stationary regime of `time/fps`. You should see a performance increase when adding the first few environments, followed by a declined when there are two many parallel processes compared to your number of CPU cores. Pick the value that works best for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6d7e4-fec4-479f-8011-d044b4693a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
